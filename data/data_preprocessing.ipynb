{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "944de076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019_processed.json\n",
      "2017_processed.json\n",
      "2018_processed.json\n",
      "2023_processed.json\n",
      "2022_processed.json\n",
      "2020_processed.json\n",
      "2021_processed.json\n",
      "Saved 100428 rows to news_prices.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json as _json\n",
    "\n",
    "\n",
    "def article_to_rows(article: dict) -> list[dict]:\n",
    "    rows = []\n",
    "\n",
    "    # ---- extract high-confidence entity words (article-level) ----\n",
    "    entities = [\n",
    "        ent[\"word\"]\n",
    "        for ent in article.get(\"named_entities\", [])\n",
    "        if ent.get(\"score\", 0) > 0.8 and \"word\" in ent\n",
    "    ]\n",
    "    \n",
    "    mentioned = article.get(\"mentioned_companies\", [])\n",
    "    related = article.get(\"related_companies\", [])\n",
    "    industries = article.get(\"industries\", [])\n",
    "    \n",
    "    \n",
    "\n",
    "    # serialize for CSV\n",
    "    entities_json = _json.dumps(entities, ensure_ascii=False)\n",
    "    mentioned_json = _json.dumps(mentioned, ensure_ascii=False)\n",
    "    related_json = _json.dumps(related, ensure_ascii=False)\n",
    "    industries_json = _json.dumps(industries, ensure_ascii=False)\n",
    "\n",
    "    sentiment = article.get(\"sentiment\", {})\n",
    "    emotion = article.get(\"emotion\", {})\n",
    "\n",
    "    base_fields = {\n",
    "        \"date_publish\": article.get(\"date_publish\"),\n",
    "        \"date_download\": article.get(\"date_download\"),\n",
    "        \"source_domain\": article.get(\"source_domain\"),\n",
    "        \"news_outlet\": article.get(\"news_outlet\"),\n",
    "        \"title\": article.get(\"title\"),\n",
    "        \"description\": article.get(\"description\"),\n",
    "        \"maintext\": article.get(\"maintext\"),\n",
    "        \"url\": article.get(\"url\"),\n",
    "        \"language\": article.get(\"language\"),\n",
    "\n",
    "        # sentiment (article-level)\n",
    "        \"sentiment_negative\": sentiment.get(\"negative\"),\n",
    "        \"sentiment_neutral\": sentiment.get(\"neutral\"),\n",
    "        \"sentiment_positive\": sentiment.get(\"positive\"),\n",
    "\n",
    "        # emotion (article-level)\n",
    "        \"emotion_anger\": emotion.get(\"anger\"),\n",
    "        \"emotion_fear\": emotion.get(\"fear\"),\n",
    "        \"emotion_joy\": emotion.get(\"joy\"),\n",
    "        \"emotion_sadness\": emotion.get(\"sadness\"),\n",
    "        \"emotion_disgust\": emotion.get(\"disgust\"),\n",
    "        \"emotion_surprise\": emotion.get(\"surprise\"),\n",
    "        \"emotion_neutral\": emotion.get(\"neutral\"),\n",
    "\n",
    "        # named entities (article-level)\n",
    "        \"named_entities\": entities_json,\n",
    "        \"mentioned_companies\": mentioned_json,\n",
    "        \"related_companies\": related_json,\n",
    "        \"industries\": industries_json\n",
    "    }\n",
    "\n",
    "    for ticker in article.get(\"mentioned_companies\", []):\n",
    "        rows.append({\n",
    "            **base_fields,\n",
    "            \"ticker\": ticker,\n",
    "            \"prev_day_price\": article.get(f\"prev_day_price_{ticker}\"),\n",
    "            \"curr_day_price\": article.get(f\"curr_day_price_{ticker}\"),\n",
    "            \"next_day_price\": article.get(f\"next_day_price_{ticker}\"),\n",
    "        })\n",
    "\n",
    "    return rows\n",
    "\n",
    "\n",
    "\n",
    "def jsons_to_csv(output_csv=\"news_prices.csv\"):\n",
    "    all_rows = []\n",
    "\n",
    "    for path in Path(\".\").glob(\"*.json\"):\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            print(f.name)\n",
    "            data = _json.load(f)\n",
    "\n",
    "        if isinstance(data, list):\n",
    "            for article in data:\n",
    "                all_rows.extend(article_to_rows(article))\n",
    "        else:\n",
    "            all_rows.extend(article_to_rows(data))\n",
    "\n",
    "    df = pd.DataFrame(all_rows)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "\n",
    "    print(f\"Saved {len(df)} rows to {output_csv}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    jsons_to_csv()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
